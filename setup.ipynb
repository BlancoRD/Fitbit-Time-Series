{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title - Fitbit Time Series Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deliverables\n",
    "\n",
    "1. Notebook: \n",
    "> material & methods, include data preparation, summary/ data dictionary\n",
    ">\n",
    "> \n",
    ">\n",
    "> analyses\n",
    ">\n",
    "> conclusions\n",
    ">\n",
    "> predictions: \n",
    ">\n",
    "> missing two weeks worth of data (csv file)\n",
    "> \n",
    "> include comment about the individual who was wearing this fitness tracker\n",
    "\n",
    "2. Prediction result: missing two weeks worth of data (csv file)\n",
    "\n",
    "3. 2 slides, audience = a general audience. \n",
    "> Include at least one visualization, clearly labeled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore and Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return (df.assign(ds=pd.to_datetime(df.Month_Invoiced)).sort_values('ds')\n",
    "            .assign(y=df.Amount)\\\n",
    "            .groupby(['ds'])['y'].sum().reset_index().set_index('ds'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prep_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_store_data(df, train_prop): \n",
    "    train_size = int(len(df) * train_prop)\n",
    "    train, test = df[0:train_size].reset_index(), df[train_size:len(df)].reset_index()\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_store_data(df2, train_prop=.80)\n",
    "\n",
    "print('Observations: %d' % (len(df2)))\n",
    "print('Training Observations: %d' % (len(train)))\n",
    "print('Testing Observations: %d' % (len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.set_index('ds')\n",
    "test = test.set_index('ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peek data\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(train)\n",
    "plt.plot(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(target_var, train = train, test = test, output=True):\n",
    "    mse = metrics.mean_squared_error(test[target_var], yhat[target_var])\n",
    "    rmse = math.sqrt(mse)\n",
    "\n",
    "    if output:\n",
    "        print('MSE:  {}'.format(mse))\n",
    "        print('RMSE: {}'.format(rmse))\n",
    "    else:\n",
    "        return mse, rmse\n",
    "\n",
    "def plot_and_eval(target_vars, train = train, test = test, metric_fmt = '{:.2f}', linewidth = 4):\n",
    "    if type(target_vars) is not list:\n",
    "        target_vars = [target_vars]\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.plot(train[target_vars],label='Train')\n",
    "    plt.plot(test[target_vars], label='Test')\n",
    "\n",
    "    for var in target_vars:\n",
    "        mse, rmse = evaluate(target_var = var, train = train, test = test, output=False)\n",
    "        plt.plot(yhat[var], linewidth=linewidth)\n",
    "        print(f'{var} -- MSE: {metric_fmt} RMSE: {metric_fmt}'.format(mse, rmse))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.DataFrame(columns=['model_type', 'target_var', 'metric', 'value'])\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df to store MSE & RMSE\n",
    "def append_eval_df(model_type, target_vars, train = train, test = test):\n",
    "    temp_eval_df = pd.concat([pd.DataFrame([[model_type, i, 'mse', evaluate(target_var = i, \n",
    "                                                                            train = train, \n",
    "                                                                            test = test, \n",
    "                                                                            output=False)[0]],\n",
    "                                            [model_type, i, 'rmse', evaluate(target_var = i, \n",
    "                                                                             train = train, \n",
    "                                                                             test = test, \n",
    "                                                                             output=False)[1]]],\n",
    "                                           columns=['model_type', 'target_var', 'metric', 'value']) \n",
    "                              for i in target_vars], ignore_index=True)\n",
    "    return eval_df.append(temp_eval_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = 30\n",
    "yhat['y'] = train.y.rolling(periods).mean().iloc[-1]\n",
    "\n",
    "# plot_and_eval(target_vars, train, test)\n",
    "# eval_df = append_eval_df(model_type='moving_average', target_vars=['y'], train = train, test = test)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(train[target_vars],label='Train')\n",
    "plt.plot(test[target_vars], label='Test')\n",
    "period_vals = [1, 4, 12, 26, 52, 104]\n",
    "for p in period_vals:\n",
    "    yhat['y'] = train.y.rolling(p).mean().iloc[-1]\n",
    "    plt.plot(yhat.y)\n",
    "    print('\\nrolling averge period:',p)\n",
    "    print('\\nitem sales\\n')\n",
    "    evaluate('y', train = train, test = test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
